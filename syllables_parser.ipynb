{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import rnn_cell\n",
    "import numpy as np\n",
    "import re\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! rm -rf checkpoints; mkdir checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SyllableParser(object):\n",
    "    \n",
    "\n",
    "    def __init__(self, num_epochs=100, batch_size=20, hidden_size=128, cell_type='lstm',\n",
    "                 net_type='brnn', num_layers=3, treshold=0.5):\n",
    "        self.num_epochs = num_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.cell_type = cell_type\n",
    "        self.num_layers = num_layers\n",
    "        self.net_type=net_type\n",
    "        self.treshold = treshold\n",
    "    \n",
    "    def encode(self, word):\n",
    "        return list(map(lambda x: self.mapping.index(x), list(word.strip().lower())))\n",
    "    \n",
    "    def decode(self, encoded_word):\n",
    "        return ''.join(map(lambda x : self.mapping[x], list(map(int,encoded_word))))\n",
    "    \n",
    "    def encode_syllables(self, syllables):\n",
    "        encoded_syllables = []\n",
    "        for syllable in syllables:\n",
    "            if len(syllable.strip()) > 0:\n",
    "                encoded_syllables.extend([0] * (len(syllable.strip()) - 1) + [1])\n",
    "        return encoded_syllables\n",
    "    \n",
    "    def pad_into_matrix(self, rows, padding_val=0):\n",
    "        matrix = []\n",
    "        lengths = np.array(list(map(len, rows)))\n",
    "        matrix_width = np.max(lengths)\n",
    "    \n",
    "        for row in rows:\n",
    "            if len(row) < matrix_width:\n",
    "                matrix.append(np.hstack((np.array(row), np.array([padding_val] * (matrix_width - len(row))))))\n",
    "            else:\n",
    "                matrix.append(np.array(row))\n",
    "        matrix = np.vstack(matrix)\n",
    "        return matrix, lengths\n",
    "    \n",
    "    def fit_data(self, filename):\n",
    "        with open(filename) as fin:\n",
    "            self.mapping = list(set(list(''.join(fin.readlines()))))\n",
    "            fin.seek(0)\n",
    "            X = []\n",
    "            y = []\n",
    "            for idx, line in enumerate(fin):\n",
    "                if idx == 0:\n",
    "                    continue  # this is csv header\n",
    "                tokens = re.split(r'\\t', line)\n",
    "                encoded_word = self.encode(tokens[0])\n",
    "                encoded_syllables = self.encode_syllables(re.split(r'\\s+', tokens[1]))\n",
    "                X.append(encoded_word)\n",
    "                y.append(encoded_syllables)\n",
    "            self.X, self.lengths = X, list(map(len, X))\n",
    "            self.y = y\n",
    "    \n",
    "    def prepare_test_data(self, filename):\n",
    "        X = []\n",
    "        with open(filename) as fin:\n",
    "            for line in fin:\n",
    "                X.append(self.encode(line))\n",
    "        self.X_test, self.test_lengths =  X, list(map(len, X))\n",
    "    \n",
    "    def decode_prediction(self, words, predicted_labels, lengths):\n",
    "        items = []\n",
    "        for i in range(len(words)):\n",
    "            word, pred, length = words[i], predicted_labels[i], lengths[i]\n",
    "            syllables = []\n",
    "            syllable = []\n",
    "            for ch, idx in zip(list(self.decode(word[:length])), pred[:length]):\n",
    "                if idx == 0:\n",
    "                    syllable.append(ch)\n",
    "                if idx == 1:\n",
    "                    syllable.append(ch)\n",
    "                    syllables.append(''.join(syllable))\n",
    "                    syllable=[]\n",
    "            if len(syllable) > 0:\n",
    "                syllables.append(''.join(syllable))\n",
    "            items.append((self.decode(word[:length]), syllables))\n",
    "        return items\n",
    "    \n",
    "    def get_batches(self, mode):\n",
    "        train_size = int(0.9 * len(self.X))\n",
    "        if mode == 'train':\n",
    "            X, y, lengths = self.X[:train_size], self.y[:train_size], self.lengths[:train_size]\n",
    "        elif mode == 'val':\n",
    "            X, y, lengths = self.X[train_size:], self.y[train_size:], self.lengths[train_size:]\n",
    "        elif mode == 'test':\n",
    "            X, y, lengths = self.X_test, self.y[:len(self.X_test)], self.test_lengths\n",
    "        else:\n",
    "            raise ValueError('Unknown mode.')\n",
    "        X_batch, y_batch, lengths_batch = [], [], []\n",
    "        for idx, x_sample in enumerate(X):\n",
    "            if idx > 0 and idx % self.batch_size == 0:\n",
    "                X_batch, lengths_batch = self.pad_into_matrix(X_batch, 0)\n",
    "                y_batch, _ = self.pad_into_matrix(y_batch, 0)\n",
    "                yield X_batch, y_batch, lengths_batch\n",
    "                X_batch, y_batch, lengths_batch = [], [], []\n",
    "            X_batch.append(x_sample)\n",
    "            y_batch.append(y[idx])\n",
    "            lengths_batch.append(lengths[idx])\n",
    "    \n",
    "    def accuracy(self, true_syllables, pred_syllables, seq_lengths):\n",
    "        num_true_predictions = 0\n",
    "        for i in range(len(true_syllables)):\n",
    "            length = seq_lengths[i]\n",
    "            true_syllable, pred_syllable = true_syllables[i, :length], pred_syllables[i, :length]\n",
    "            if np.all(np.equal(true_syllable, pred_syllable)):\n",
    "                num_true_predictions += 1\n",
    "        # results = np.all(np.equal(true_syllables, pred_syllables), axis=1)\n",
    "        # true_predictions = len(results[results == True])\n",
    "        return num_true_predictions / float(len(true_syllables))\n",
    "    \n",
    "    def construct_graph(self):\n",
    "        self.graph = tf.Graph()\n",
    "        hidden_state_size = self.hidden_size\n",
    "        if self.net_type == 'brnn':\n",
    "            hidden_state_size *= 2\n",
    "        with self.graph.as_default():\n",
    "            self.words = tf.placeholder(tf.int32, shape=(self.batch_size, None), name='words')\n",
    "            self.syllable_labels = tf.placeholder(tf.int32, shape=(self.batch_size, None), name='syllable_labels')\n",
    "            self.seq_lengths = tf.placeholder(tf.int32, shape=(self.batch_size), name='lengths')\n",
    "            W = tf.Variable(tf.truncated_normal([hidden_state_size, 2]), dtype=tf.float32)\n",
    "            b = tf.Variable(np.zeros([2]), dtype=tf.float32)\n",
    "            embedding_matrix = tf.Variable(tf.truncated_normal([len(self.mapping), self.hidden_size],\n",
    "                                                               stddev=np.sqrt(2.0/ self.hidden_size)))\n",
    "            embedding = tf.nn.embedding_lookup(embedding_matrix, self.words)\n",
    "            treshold = tf.Variable(np.array([self.treshold]), dtype=tf.float32, name='treshold')\n",
    "            if self.cell_type == 'lstm':\n",
    "                cell = rnn_cell.LSTMCell(self.hidden_size)\n",
    "            elif self.cell_type == 'gru':\n",
    "                cell = rnn_cell.GRUCell(self.hidden_size)\n",
    "            else:\n",
    "                raise ValueError('Unknown cell type.')\n",
    "            rnn_multicell = rnn_cell.MultiRNNCell([cell] * self.num_layers)\n",
    "            if self.net_type == 'rnn':\n",
    "                self.outputs, _ = tf.nn.dynamic_rnn(rnn_multicell, embedding, sequence_length=self.seq_lengths,\n",
    "                                                    dtype=tf.float32, swap_memory=True)\n",
    "            elif self.net_type == 'brnn':\n",
    "                self.outputs, _ = tf.nn.bidirectional_dynamic_rnn(rnn_multicell, rnn_multicell, embedding,\n",
    "                                                                  sequence_length=self.seq_lengths,\n",
    "                                                                  dtype=tf.float32, swap_memory=True)\n",
    "                self.outputs = tf.concat(2, self.outputs)\n",
    "            # print(self.outputs.get_shape())\n",
    "            outputs_reshape = tf.reshape(self.outputs, [-1, hidden_state_size])\n",
    "            # print(outputs_reshape.get_shape())\n",
    "            # print(W.get_shape())\n",
    "            logits = tf.matmul(outputs_reshape, W) + b\n",
    "            self.logits = tf.reshape(logits, [self.batch_size, -1, 2])\n",
    "            # print(self.logits.get_shape())\n",
    "            # print(self.syllable_labels.get_shape())\n",
    "            # self.prediction = tf.argmax(self.logits, 2)\n",
    "            probs = tf.nn.softmax(self.logits)\n",
    "            # print(probs.get_shape())\n",
    "            sliced_probs = tf.slice(probs, [0, 0, 1], [-1,-1,-1])\n",
    "            greater = tf.greater(sliced_probs, treshold)\n",
    "            # print(greater.get_shape())\n",
    "            self.separation_indices = tf.where(greater)\n",
    "            self.prediction = tf.zeros_like(greater)\n",
    "            # print(sliced_probs.get_shape())\n",
    "            # print(self.prediction.get_shape())\n",
    "            self.loss = (tf.reduce_sum(tf.nn.sparse_softmax_cross_entropy_with_logits(self.logits, self.syllable_labels)*\n",
    "                                       tf.sequence_mask(self.seq_lengths, tf.reduce_max(self.seq_lengths),\n",
    "                                                        dtype=tf.float32)) /\n",
    "                         tf.reduce_sum(tf.sequence_mask(self.seq_lengths, tf.reduce_max(self.seq_lengths),\n",
    "                                                        dtype=tf.float32)))\n",
    "            self.optimizer = tf.train.AdamOptimizer().minimize(self.loss)\n",
    "            self.saver = tf.train.Saver()\n",
    "\n",
    "    def run_session(self, checkpoints_dir):\n",
    "        with self.graph.as_default():\n",
    "            self.session = tf.Session()\n",
    "            self.session.run(tf.initialize_all_variables())\n",
    "            print(\"Checking for checkpoints...\")\n",
    "            latest_checkpoint = tf.train.latest_checkpoint(checkpoints_dir)\n",
    "            if latest_checkpoint is not None:\n",
    "                print(\"Found checkpoints, using them.\")\n",
    "                self.saver.restore(self.session, latest_checkpoint)\n",
    "            else:\n",
    "                print(\"No checkpoints found, starting training from scratch.\")\n",
    "            for epoch in range(self.num_epochs):\n",
    "                print(\"Starting epoch {}\".format(epoch))\n",
    "                batch_losses = []\n",
    "                start = time()\n",
    "                for words_batch, syllable_labels_batch, lengths_batch in self.get_batches('train'):\n",
    "                    feed_dict = {self.words: words_batch, self.syllable_labels: syllable_labels_batch,\n",
    "                                 self.seq_lengths: lengths_batch}\n",
    "                    if words_batch.shape != syllable_labels_batch.shape:\n",
    "                        prediction = self.decode_prediction(words_batch,\n",
    "                                                            syllable_labels_batch, lengths_batch)\n",
    "                        print(\"Bad train examples:\")\n",
    "                        for word, syllables in prediction:\n",
    "                            print('\\t', word, ' '.join(syllables))\n",
    "\n",
    "                    batch_loss, _ = self.session.run([self.loss, self.optimizer], feed_dict=feed_dict)\n",
    "                    batch_losses.append(batch_loss)\n",
    "                end = time()\n",
    "                print('Epoch {} done. Loss: {}. Training took {} sec.'.format(epoch, np.mean(batch_losses),\n",
    "                                                                              end - start))\n",
    "                val_losses = []\n",
    "                for val_words_batch, val_syllable_labels_batch, val_lengths_batch in self.get_batches('val'):\n",
    "                    feed_dict = {self.words: val_words_batch, self.syllable_labels: val_syllable_labels_batch,\n",
    "                                 self.seq_lengths: val_lengths_batch}\n",
    "                    pred, indices, val_loss = self.session.run([self.prediction, self.separation_indices, self.loss],\n",
    "                                                               feed_dict=feed_dict)\n",
    "                    pred[indices[:, 0], indices[:, 1], indices[:, 2]] = 1\n",
    "                    val_losses.append(val_loss)\n",
    "                    pred = pred.reshape((pred.shape[0], pred.shape[1])).astype(np.int32)\n",
    "                print('Validation loss: {}'.format(np.mean(val_losses)))\n",
    "                print('Accuracy: {}'.format(self.accuracy(val_syllable_labels_batch, pred, val_lengths_batch)))\n",
    "                sample_indices = np.random.choice(np.arange(len(val_words_batch)), 3)\n",
    "                prediction = self.decode_prediction(val_words_batch[sample_indices],\n",
    "                                                    pred[sample_indices], val_lengths_batch[sample_indices])\n",
    "                true_values = self.decode_prediction(val_words_batch[sample_indices],\n",
    "                                                     val_syllable_labels_batch[sample_indices],\n",
    "                                                     val_lengths_batch[sample_indices])\n",
    "                # print(pred[sample_indices], val_syllable_labels_batch[sample_indices])\n",
    "                print(\"Sample predictions:\")\n",
    "                for (word, syllables), (word, true_syllables) in zip(prediction, true_values):\n",
    "                    print('\\t', word, ' '.join(syllables), ' '.join(true_syllables))\n",
    "                if epoch % 10 == 0:\n",
    "                    print(\"Saving model...\")\n",
    "                    save_path = self.saver.save(self.session, os.path.join(checkpoints_dir,\n",
    "                                                \"checkpoint\" + datetime.now().strftime(\"_%d.%m.%y_%H:%M\") ))\n",
    "                    print(\"Saved in \" + save_path)\n",
    "    \n",
    "    def train(self, filename, checkpoints_dir):\n",
    "        self.fit_data(filename)\n",
    "        self.construct_graph()\n",
    "        self.run_session(checkpoints_dir)\n",
    "        return self.session # for further sampling\n",
    "    \n",
    "    def sample(self, session, filename, out_file='output.txt'):\n",
    "        self.prepare_test_data(filename)\n",
    "        with open(out_file, 'w') as fout:\n",
    "            with self.graph.as_default():\n",
    "                print('Sampling...')\n",
    "                for words_batch, syllable_labels_batch, lengths_batch in self.get_batches('test'):\n",
    "                    feed_dict = {self.words: words_batch, self.syllable_labels: syllable_labels_batch,\n",
    "                                 self.seq_lengths: lengths_batch}\n",
    "                    pred, indices = session.run([self.prediction, self.separation_indices], feed_dict=feed_dict)\n",
    "                    pred[indices[:, 0], indices[:, 1], indices[:, 2]] = 1\n",
    "                    prediction = self.decode_prediction(words_batch, pred, lengths_batch)\n",
    "                    for word, syllables in prediction:\n",
    "                        print(word, ' '.join(syllables))\n",
    "                        fout.write(word + ' ' +  ' '.join(syllables) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for checkpoints...\n",
      "No checkpoints found, starting training from scratch.\n",
      "Starting epoch 0\n",
      "Epoch 0 done. Loss: 0.2647058367729187. Training took 14.024769067764282 sec.\n",
      "Validation loss: 0.12295219302177429\n",
      "Accuracy: 0.645\n",
      "Sample predictions:\n",
      "\t прочнеть проч неть проч неть\n",
      "\t примереть при ме реть при ме реть\n",
      "\t депроприация де про п ри а ци я де про при а ци я\n",
      "Saving model...\n",
      "Saved in checkpoints/checkpoint_09.11.16_15:22\n",
      "Starting epoch 1\n",
      "Epoch 1 done. Loss: 0.09427566826343536. Training took 13.886988878250122 sec.\n",
      "Validation loss: 0.17933526635169983\n",
      "Accuracy: 0.56\n",
      "Sample predictions:\n",
      "\t филлипика фил ли пи ка фил ли пи ка\n",
      "\t антипрусский ан ти п рус с кий ан ти прус ский\n",
      "\t подюжить по дю жить по дю жить\n",
      "Starting epoch 2\n",
      "Epoch 2 done. Loss: 0.08523307740688324. Training took 13.929564476013184 sec.\n",
      "Validation loss: 0.15520554780960083\n",
      "Accuracy: 0.58\n",
      "Sample predictions:\n",
      "\t падали па да ли па да ли\n",
      "\t госнии гос ни и госнии\n",
      "\t патогенность па то ген ность па то ген ность\n",
      "Starting epoch 3\n",
      "Epoch 3 done. Loss: 0.08066700398921967. Training took 13.915858268737793 sec.\n",
      "Validation loss: 0.10830973088741302\n",
      "Accuracy: 0.685\n",
      "Sample predictions:\n",
      "\t всклянь всклянь всклянь\n",
      "\t гарибальдиец га ри ба ль ди ец га ри баль ди ец\n",
      "\t филлипика фил ли пи ка фил ли пи ка\n",
      "Starting epoch 4\n",
      "Epoch 4 done. Loss: 0.07660634815692902. Training took 13.916804790496826 sec.\n",
      "Validation loss: 0.09261959791183472\n",
      "Accuracy: 0.715\n",
      "Sample predictions:\n",
      "\t троил тро ил тро ил\n",
      "\t осиветь о си веть о си веть\n",
      "\t хрустик хрустик хрус тик\n",
      "Starting epoch 5\n",
      "Epoch 5 done. Loss: 0.07322057336568832. Training took 13.880476951599121 sec.\n",
      "Validation loss: 0.08509869873523712\n",
      "Accuracy: 0.74\n",
      "Sample predictions:\n",
      "\t поколеть по ко леть по ко леть\n",
      "\t депроприатив деп ро при а тив де про при а тив\n",
      "\t ингибирование ин ги би ро ва ни е ин ги би ро ва ни е\n",
      "Starting epoch 6\n",
      "Epoch 6 done. Loss: 0.0702587217092514. Training took 13.882845640182495 sec.\n",
      "Validation loss: 0.07975170016288757\n",
      "Accuracy: 0.775\n",
      "Sample predictions:\n",
      "\t теплозатрата теп ло зат ра та теп ло за тра та\n",
      "\t креатинфосфокиназа кре а тин фос фо ки на за кре а тин фос фо ки на за\n",
      "\t узкосословный уз ко сослов ный уз ко со слов ный\n",
      "Starting epoch 7\n",
      "Epoch 7 done. Loss: 0.06765691936016083. Training took 13.871031999588013 sec.\n",
      "Validation loss: 0.07613557577133179\n",
      "Accuracy: 0.79\n",
      "Sample predictions:\n",
      "\t потарахтеть по та рах теть по та рах теть\n",
      "\t онкогенность он ко ген ность он ко ген ность\n",
      "\t онкогенность он ко ген ность он ко ген ность\n",
      "Starting epoch 8\n",
      "Epoch 8 done. Loss: 0.06544285267591476. Training took 13.889801263809204 sec.\n",
      "Validation loss: 0.07473631948232651\n",
      "Accuracy: 0.785\n",
      "Sample predictions:\n",
      "\t антипрусский ан ти прус ский ан ти прус ский\n",
      "\t богатейский бо га тей ский бо га тей ский\n",
      "\t креатинкиназа кре а тин ки на за кре а тин ки на за\n",
      "Starting epoch 9\n",
      "Epoch 9 done. Loss: 0.06340938806533813. Training took 13.899087905883789 sec.\n",
      "Validation loss: 0.07448601722717285\n",
      "Accuracy: 0.795\n",
      "Sample predictions:\n",
      "\t троил тро ил тро ил\n",
      "\t несъёжившийся не съ ё жив ший ся не съё жив ший ся\n",
      "\t кабелерез ка бе ле рез ка бе ле рез\n",
      "Starting epoch 10\n",
      "Epoch 10 done. Loss: 0.06151553615927696. Training took 13.889456748962402 sec.\n",
      "Validation loss: 0.07551570236682892\n",
      "Accuracy: 0.8\n",
      "Sample predictions:\n",
      "\t узкосословный уз ко со слов ный уз ко со слов ный\n",
      "\t теплозатрата теп ло за т ра та теп ло за тра та\n",
      "\t лексикализировать лек си ка ли зи ро вать лек си ка ли зи ро вать\n",
      "Saving model...\n",
      "Saved in checkpoints/checkpoint_09.11.16_15:24\n",
      "Starting epoch 11\n",
      "Epoch 11 done. Loss: 0.05955817177891731. Training took 13.954301118850708 sec.\n",
      "Validation loss: 0.0768008604645729\n",
      "Accuracy: 0.785\n",
      "Sample predictions:\n",
      "\t хрястаться хряс та ть ся хря ста ться\n",
      "\t дирк дирк дирк\n",
      "\t антипрусский ан ти прус ский ан ти прус ский\n",
      "Starting epoch 12\n",
      "Epoch 12 done. Loss: 0.05788211524486542. Training took 13.951885223388672 sec.\n",
      "Validation loss: 0.07882452756166458\n",
      "Accuracy: 0.78\n",
      "Sample predictions:\n",
      "\t аспарагинат аспа ра ги нат ас па ра ги нат\n",
      "\t сленгизм слен гизм слен гизм\n",
      "\t диковать ди ко вать ди ко вать\n",
      "Starting epoch 13\n",
      "Epoch 13 done. Loss: 0.05618319660425186. Training took 13.901583909988403 sec.\n",
      "Validation loss: 0.08001817762851715\n",
      "Accuracy: 0.765\n",
      "Sample predictions:\n",
      "\t диковать ди ко вать ди ко вать\n",
      "\t финансово фи нан со во фи нан со во\n",
      "\t иллокутивность ил ло ку тив ность ил ло ку тив ность\n",
      "Starting epoch 14\n",
      "Epoch 14 done. Loss: 0.054702308028936386. Training took 13.946710109710693 sec.\n",
      "Validation loss: 0.08094547688961029\n",
      "Accuracy: 0.77\n",
      "Sample predictions:\n",
      "\t тромбообразование тром бо об ра зо ва ни е тром бо об ра зо ва ни е\n",
      "\t богатейский бо га тей ский бо га тей ский\n",
      "\t финансово фи нан со во фи нан со во\n",
      "Starting epoch 15\n",
      "Epoch 15 done. Loss: 0.053058888763189316. Training took 13.955764770507812 sec.\n",
      "Validation loss: 0.08380486071109772\n",
      "Accuracy: 0.755\n",
      "Sample predictions:\n",
      "\t субстантив суб стан тив суб стан тив\n",
      "\t гарибальдиец га ри баль ди ец га ри баль ди ец\n",
      "\t плес плес плес\n",
      "Starting epoch 16\n",
      "Epoch 16 done. Loss: 0.05142144858837128. Training took 13.939720869064331 sec.\n",
      "Validation loss: 0.0870155394077301\n",
      "Accuracy: 0.765\n",
      "Sample predictions:\n",
      "\t снарядник сна ряд ник сна ряд ник\n",
      "\t чертившийся чер тив ший ся чер тив ший ся\n",
      "\t недооцениться не до о це ни ть ся не до о це нить ся\n",
      "Starting epoch 17\n",
      "Epoch 17 done. Loss: 0.04964667186141014. Training took 13.934756755828857 sec.\n",
      "Validation loss: 0.0924530178308487\n",
      "Accuracy: 0.745\n",
      "Sample predictions:\n",
      "\t стэк стэк стэк\n",
      "\t хуинушка ху и нуш ка ху и ну шка\n",
      "\t поколеть по ко леть по ко леть\n",
      "Starting epoch 18\n",
      "Epoch 18 done. Loss: 0.04798275977373123. Training took 13.87775993347168 sec.\n",
      "Validation loss: 0.09667222201824188\n",
      "Accuracy: 0.755\n",
      "Sample predictions:\n",
      "\t ошепеляветь о ше пе ля веть о ше пе ля веть\n",
      "\t брэд брэд брэд\n",
      "\t пидорок пи до рок пи до рок\n",
      "Starting epoch 19\n",
      "Epoch 19 done. Loss: 0.04614698886871338. Training took 13.888613939285278 sec.\n",
      "Validation loss: 0.1016569584608078\n",
      "Accuracy: 0.76\n",
      "Sample predictions:\n",
      "\t вертикализация вер ти ка ли за ци я вер ти ка ли за ци я\n",
      "\t межпоселенческий меж по се лен че ский меж по се лен чес кий\n",
      "\t дипилонский ди пи лон ский ди пи лон ский\n",
      "Starting epoch 20\n",
      "Epoch 20 done. Loss: 0.0446457639336586. Training took 13.92136549949646 sec.\n",
      "Validation loss: 0.10103271156549454\n",
      "Accuracy: 0.77\n",
      "Sample predictions:\n",
      "\t несъёжившийся не съ ё жи в ший ся не съё жив ший ся\n",
      "\t дошивать до ши вать до ши вать\n",
      "\t посвиристеть по сви рис теть по сви рис теть\n",
      "Saving model...\n",
      "Saved in checkpoints/checkpoint_09.11.16_15:26\n",
      "Starting epoch 21\n",
      "Epoch 21 done. Loss: 0.04315533861517906. Training took 13.96610140800476 sec.\n",
      "Validation loss: 0.10075493156909943\n",
      "Accuracy: 0.76\n",
      "Sample predictions:\n",
      "\t мембот мем бот мем бот\n",
      "\t михайловский ми хай лов ский ми хай лов ский\n",
      "\t йыгъ йыгъ йыгъ\n",
      "Starting epoch 22\n",
      "Epoch 22 done. Loss: 0.040520403534173965. Training took 13.943257570266724 sec.\n",
      "Validation loss: 0.09929920732975006\n",
      "Accuracy: 0.76\n",
      "Sample predictions:\n",
      "\t автомобилистский ав то мо би лист ский ав то мо би лист ский\n",
      "\t запрятывать за пря ты вать за пря ты вать\n",
      "\t теплозатрата те п ло за тра та теп ло за тра та\n",
      "Starting epoch 23\n",
      "Epoch 23 done. Loss: 0.03867882117629051. Training took 13.959651708602905 sec.\n",
      "Validation loss: 0.102489173412323\n",
      "Accuracy: 0.775\n",
      "Sample predictions:\n",
      "\t штормгласс шторм гласс шторм гласс\n",
      "\t креатинкиназа кре а т ин ки на за кре а тин ки на за\n",
      "\t ссять ссять ссять\n",
      "Starting epoch 24\n",
      "Epoch 24 done. Loss: 0.036649562418460846. Training took 13.951546430587769 sec.\n",
      "Validation loss: 0.1042894572019577\n",
      "Accuracy: 0.77\n",
      "Sample predictions:\n",
      "\t чертившийся чер тив ший ся чер тив ший ся\n",
      "\t хуёчек ху ё чек ху ё чек\n",
      "\t всклянь всклянь всклянь\n",
      "Starting epoch 25\n",
      "Epoch 25 done. Loss: 0.03435029089450836. Training took 13.895099401473999 sec.\n",
      "Validation loss: 0.10513532161712646\n",
      "Accuracy: 0.755\n",
      "Sample predictions:\n",
      "\t всклянь всклянь всклянь\n",
      "\t ссять ссять ссять\n",
      "\t коме ко ме ко ме\n",
      "Starting epoch 26\n",
      "Epoch 26 done. Loss: 0.032589931041002274. Training took 13.92893671989441 sec.\n",
      "Validation loss: 0.11018941551446915\n",
      "Accuracy: 0.76\n",
      "Sample predictions:\n",
      "\t штормгласс шторм гласс шторм гласс\n",
      "\t типок ти пок ти пок\n",
      "\t снарядник сна ряд ник сна ряд ник\n",
      "Starting epoch 27\n",
      "Epoch 27 done. Loss: 0.030506284907460213. Training took 13.961530447006226 sec.\n",
      "Validation loss: 0.11244113743305206\n",
      "Accuracy: 0.78\n",
      "Sample predictions:\n",
      "\t горю го рю горю\n",
      "\t диковать ди ко вать ди ко вать\n",
      "\t остеоклазия осте о кла зи я ос те о кла зи я\n",
      "Starting epoch 28\n",
      "Epoch 28 done. Loss: 0.029397236183285713. Training took 13.953494310379028 sec.\n",
      "Validation loss: 0.11097991466522217\n",
      "Accuracy: 0.77\n",
      "Sample predictions:\n",
      "\t теплозатрата теп ло за тра та теп ло за тра та\n",
      "\t алюмогелевый а лю мо ге ле вый а лю мо ге ле вый\n",
      "\t калифорнийка ка ли фор ний ка ка ли фор ний ка\n",
      "Starting epoch 29\n",
      "Epoch 29 done. Loss: 0.02719257026910782. Training took 13.923505783081055 sec.\n",
      "Validation loss: 0.11185511201620102\n",
      "Accuracy: 0.755\n",
      "Sample predictions:\n",
      "\t препуциопластика пре пу ци о пласти ка пре пу ци о пла сти ка\n",
      "\t осиветь о сиветь о си веть\n",
      "\t михайловский ми хай лов ский ми хай лов ский\n",
      "Starting epoch 30\n",
      "Epoch 30 done. Loss: 0.02534220926463604. Training took 13.9366135597229 sec.\n",
      "Validation loss: 0.1160224974155426\n",
      "Accuracy: 0.77\n",
      "Sample predictions:\n",
      "\t эзов эзов эзов\n",
      "\t хуина ху и на ху и на\n",
      "\t бередя бе ре дя бе ре дя\n",
      "Saving model...\n",
      "Saved in checkpoints/checkpoint_09.11.16_15:29\n",
      "Starting epoch 31\n",
      "Epoch 31 done. Loss: 0.02342134341597557. Training took 13.880100727081299 sec.\n",
      "Validation loss: 0.1205848976969719\n",
      "Accuracy: 0.78\n",
      "Sample predictions:\n",
      "\t микромем мик ро мем мик ро мем\n",
      "\t интерлиньяжный ин тер линь яж ный ин тер линь яж ный\n",
      "\t дипломирование ди пло ми ро ва ни е ди пло ми ро ва ни е\n",
      "Starting epoch 32\n",
      "Epoch 32 done. Loss: 0.02201099321246147. Training took 13.871254444122314 sec.\n",
      "Validation loss: 0.12353923916816711\n",
      "Accuracy: 0.75\n",
      "Sample predictions:\n",
      "\t гастролит га с тро лит га стро лит\n",
      "\t уязвиться у яз вить ся у яз вить ся\n",
      "\t маркирующий мар ки ру ю щий мар ки ру ю щий\n",
      "Starting epoch 33\n",
      "Epoch 33 done. Loss: 0.020730577409267426. Training took 13.884334087371826 sec.\n",
      "Validation loss: 0.12497169524431229\n",
      "Accuracy: 0.745\n",
      "Sample predictions:\n",
      "\t несмеющийся не сме ю щий ся не сме ю щий ся\n",
      "\t несмеющийся не сме ю щий ся не сме ю щий ся\n",
      "\t хуёчек ху ё чек ху ё чек\n",
      "Starting epoch 34\n",
      "Epoch 34 done. Loss: 0.01955115608870983. Training took 13.877961874008179 sec.\n",
      "Validation loss: 0.12821552157402039\n",
      "Accuracy: 0.77\n",
      "Sample predictions:\n",
      "\t прагматоним праг ма то ним праг ма то ним\n",
      "\t фил фил фил\n",
      "\t душевладелец ду ше вла де лец ду ше вла де лец\n",
      "Starting epoch 35\n",
      "Epoch 35 done. Loss: 0.019614871591329575. Training took 13.88532042503357 sec.\n",
      "Validation loss: 0.12851953506469727\n",
      "Accuracy: 0.775\n",
      "Sample predictions:\n",
      "\t проприальный про при аль ный про при аль ный\n",
      "\t душевладелец ду ше вла де лец ду ше вла де лец\n",
      "\t спросонков спро сонков спро сон ков\n",
      "Starting epoch 36\n",
      "Epoch 36 done. Loss: 0.017827743664383888. Training took 13.873997449874878 sec.\n",
      "Validation loss: 0.13661077618598938\n",
      "Accuracy: 0.765\n",
      "Sample predictions:\n",
      "\t карнитин кар ни тин кар ни тин\n",
      "\t пропагандируемый про па ган ди ру е мый про па ган ди ру е мый\n",
      "\t пидорок пи до рок пи до рок\n",
      "Starting epoch 37\n",
      "Epoch 37 done. Loss: 0.01655525527894497. Training took 13.875472068786621 sec.\n",
      "Validation loss: 0.14024633169174194\n",
      "Accuracy: 0.715\n",
      "Sample predictions:\n",
      "\t несъёжившийся не съё жив ший ся не съё жив ший ся\n",
      "\t хуевый ху е вый ху е вый\n",
      "\t богаческий бо га че ский бо га чес кий\n",
      "Starting epoch 38\n",
      "Epoch 38 done. Loss: 0.015900757163763046. Training took 13.879353284835815 sec.\n",
      "Validation loss: 0.14603835344314575\n",
      "Accuracy: 0.75\n",
      "Sample predictions:\n",
      "\t подзадолбать по д за долбать под за дол бать\n",
      "\t комикку ко микку ко мик ку\n",
      "\t прочнеть прочнеть проч неть\n",
      "Starting epoch 39\n",
      "Epoch 39 done. Loss: 0.014714700169861317. Training took 13.873354434967041 sec.\n",
      "Validation loss: 0.15334539115428925\n",
      "Accuracy: 0.72\n",
      "Sample predictions:\n",
      "\t непрочитанный не про чи тан ный не про чи тан ный\n",
      "\t дипилонский ди пи лон ский ди пи лон ский\n",
      "\t полуобезумевший по лу о бе зу ме в ший по лу о бе зу мев ший\n",
      "Starting epoch 40\n",
      "Epoch 40 done. Loss: 0.014632979407906532. Training took 13.885132551193237 sec.\n",
      "Validation loss: 0.1618616282939911\n",
      "Accuracy: 0.71\n",
      "Sample predictions:\n",
      "\t гювеч гю веч гю веч\n",
      "\t озадачиться о за да чить ся о за да чить ся\n",
      "\t светопреставленье све то пре ставленье све то пре став ле нье\n",
      "Saving model...\n",
      "Saved in checkpoints/checkpoint_09.11.16_15:31\n",
      "Starting epoch 41\n",
      "Epoch 41 done. Loss: 0.01400633156299591. Training took 13.912946701049805 sec.\n",
      "Validation loss: 0.16861672699451447\n",
      "Accuracy: 0.72\n",
      "Sample predictions:\n",
      "\t запятушка за пя туш ка за пя туш ка\n",
      "\t пятиячейник пя ти я чей ник пя ти я чей ник\n",
      "\t коме ко ме ко ме\n",
      "Starting epoch 42\n",
      "Epoch 42 done. Loss: 0.01374469418078661. Training took 13.891605377197266 sec.\n",
      "Validation loss: 0.17134281992912292\n",
      "Accuracy: 0.755\n",
      "Sample predictions:\n",
      "\t горю го рю горю\n",
      "\t искусывание ис ку сы ва ни е ис ку сы ва ни е\n",
      "\t секелёк се ке лёк се ке лёк\n",
      "Starting epoch 43\n",
      "Epoch 43 done. Loss: 0.012951236218214035. Training took 13.880914688110352 sec.\n",
      "Validation loss: 0.17496508359909058\n",
      "Accuracy: 0.705\n",
      "Sample predictions:\n",
      "\t богатейский бо га тей ский бо га тей ский\n",
      "\t трудновато труд но ва то труд но ва то\n",
      "\t калофонический ка ло фо ни чес кий ка ло фо ни че ский\n",
      "Starting epoch 44\n",
      "Epoch 44 done. Loss: 0.012429757975041866. Training took 13.881731986999512 sec.\n",
      "Validation loss: 0.182790607213974\n",
      "Accuracy: 0.75\n",
      "Sample predictions:\n",
      "\t госнии гос ни и госнии\n",
      "\t расхватывание рас хва ты ва ни е рас хва ты ва ни е\n",
      "\t контрамаркированный кон тра мар ки ро ван ный кон тра мар ки ро ван ный\n",
      "Starting epoch 45\n",
      "Epoch 45 done. Loss: 0.011775648221373558. Training took 13.898810863494873 sec.\n",
      "Validation loss: 0.18177680671215057\n",
      "Accuracy: 0.745\n",
      "Sample predictions:\n",
      "\t калофония ка ло фо ни я ка ло фо ни я\n",
      "\t проклиза про кли за про кли за\n",
      "\t калофония ка ло фо ни я ка ло фо ни я\n",
      "Starting epoch 46\n",
      "Epoch 46 done. Loss: 0.011180348694324493. Training took 13.884664058685303 sec.\n",
      "Validation loss: 0.1878718137741089\n",
      "Accuracy: 0.785\n",
      "Sample predictions:\n",
      "\t обороть о бо роть о бо роть\n",
      "\t сленгизм слен гизм слен гизм\n",
      "\t несъёжившийся не съё жив ший ся не съё жив ший ся\n",
      "Starting epoch 47\n",
      "Epoch 47 done. Loss: 0.011560305021703243. Training took 13.8830406665802 sec.\n",
      "Validation loss: 0.19580276310443878\n",
      "Accuracy: 0.78\n",
      "Sample predictions:\n",
      "\t раннеголоценовый ран не го ло це но вый ран не го ло це но вый\n",
      "\t обрученница об ру чен ни ца об ру чен ни ца\n",
      "\t субстантив суб стантив суб стан тив\n",
      "Starting epoch 48\n",
      "Epoch 48 done. Loss: 0.012218440882861614. Training took 13.88687801361084 sec.\n",
      "Validation loss: 0.1860479712486267\n",
      "Accuracy: 0.74\n",
      "Sample predictions:\n",
      "\t толкач толкач толкач\n",
      "\t пропрусский про прус ский про прус ский\n",
      "\t креатинкиназа кре а тин ки на за кре а тин ки на за\n",
      "Starting epoch 49\n",
      "Epoch 49 done. Loss: 0.0111465472728014. Training took 13.894641399383545 sec.\n",
      "Validation loss: 0.19899320602416992\n",
      "Accuracy: 0.74\n",
      "Sample predictions:\n",
      "\t алюмогелевый а лю мо ге ле вый а лю мо ге ле вый\n",
      "\t посвиристеть по сви рис теть по сви рис теть\n",
      "\t перешаривать пе ре ша ри вать пе ре ша ри вать\n",
      "Starting epoch 50\n",
      "Epoch 50 done. Loss: 0.010379265062510967. Training took 13.954046249389648 sec.\n",
      "Validation loss: 0.20742151141166687\n",
      "Accuracy: 0.72\n",
      "Sample predictions:\n",
      "\t финансистка фи нан сист ка фи нан сист ка\n",
      "\t межпоселенческий меж по се лен чес кий меж по се лен чес кий\n",
      "\t облущивать об лу щи вать об лу щи вать\n",
      "Saving model...\n",
      "Saved in checkpoints/checkpoint_09.11.16_15:34\n",
      "Starting epoch 51\n",
      "Epoch 51 done. Loss: 0.010028984397649765. Training took 13.893359422683716 sec.\n",
      "Validation loss: 0.20241370797157288\n",
      "Accuracy: 0.715\n",
      "Sample predictions:\n",
      "\t остеоклазия осте о кла зи я ос те о кла зи я\n",
      "\t нехрущ не хрущ не хрущ\n",
      "\t оттопыриваться от то пы ри вать ся от то пы ри вать ся\n",
      "Starting epoch 52\n",
      "Epoch 52 done. Loss: 0.010082327760756016. Training took 13.77238130569458 sec.\n",
      "Validation loss: 0.20377354323863983\n",
      "Accuracy: 0.74\n",
      "Sample predictions:\n",
      "\t гастролит гас тро лит га стро лит\n",
      "\t гастролит гас тро лит га стро лит\n",
      "\t препуциопластика пре пу ци о пласти ка пре пу ци о пла сти ка\n",
      "Starting epoch 53\n",
      "Epoch 53 done. Loss: 0.009580480866134167. Training took 13.791643142700195 sec.\n",
      "Validation loss: 0.20140567421913147\n",
      "Accuracy: 0.735\n",
      "Sample predictions:\n",
      "\t нут нут нут\n",
      "\t онкогенность он ко ген ность он ко ген ность\n",
      "\t йыгъ йыгъ йыгъ\n",
      "Starting epoch 54\n",
      "Epoch 54 done. Loss: 0.009477308951318264. Training took 13.698529958724976 sec.\n",
      "Validation loss: 0.19825969636440277\n",
      "Accuracy: 0.765\n",
      "Sample predictions:\n",
      "\t светопреставленье све то пре став ле нье све то пре став ле нье\n",
      "\t заробить за ро бить за ро бить\n",
      "\t доверив до верив до ве рив\n",
      "Starting epoch 55\n",
      "Epoch 55 done. Loss: 0.009119227528572083. Training took 13.732259273529053 sec.\n",
      "Validation loss: 0.18643081188201904\n",
      "Accuracy: 0.745\n",
      "Sample predictions:\n",
      "\t антидворянский ан ти дво рян ский ан ти дво рян ский\n",
      "\t псил псил псил\n",
      "\t проклиза про кли за про кли за\n",
      "Starting epoch 56\n",
      "Epoch 56 done. Loss: 0.008616005070507526. Training took 13.777244091033936 sec.\n",
      "Validation loss: 0.19329304993152618\n",
      "Accuracy: 0.74\n",
      "Sample predictions:\n",
      "\t челдон челдон чел дон\n",
      "\t депроприатив де про при а тив де про при а тив\n",
      "\t отчехвостить от че хвос тить от че хвост ить\n",
      "Starting epoch 57\n",
      "Epoch 57 done. Loss: 0.008443258702754974. Training took 13.694760799407959 sec.\n",
      "Validation loss: 0.19875633716583252\n",
      "Accuracy: 0.73\n",
      "Sample predictions:\n",
      "\t подюжить по дю жить по дю жить\n",
      "\t полуобезумевший по лу о бе зу ме в ший по лу о бе зу мев ший\n",
      "\t терпковатый терп ко ва тый терп ко ва тый\n",
      "Starting epoch 58\n",
      "Epoch 58 done. Loss: 0.00797024741768837. Training took 13.697425127029419 sec.\n",
      "Validation loss: 0.21117158234119415\n",
      "Accuracy: 0.74\n",
      "Sample predictions:\n",
      "\t светопреставленье све то пре став ле нь е све то пре став ле нье\n",
      "\t запрятывание за пря ты ва ни е за пря ты ва ни е\n",
      "\t суконность су кон ность су кон ность\n",
      "Starting epoch 59\n",
      "Epoch 59 done. Loss: 0.0074673970229923725. Training took 13.712841272354126 sec.\n",
      "Validation loss: 0.21154704689979553\n",
      "Accuracy: 0.74\n",
      "Sample predictions:\n",
      "\t дипилон ди пи лон ди пи лон\n",
      "\t подзадолбать под за дол бать под за дол бать\n",
      "\t сленгизм слен гизм слен гизм\n",
      "Starting epoch 60\n",
      "Epoch 60 done. Loss: 0.007448411546647549. Training took 13.69805121421814 sec.\n",
      "Validation loss: 0.21318157017230988\n",
      "Accuracy: 0.745\n",
      "Sample predictions:\n",
      "\t проприальный про при аль ный про при аль ный\n",
      "\t финансово фи нан со во фи нан со во\n",
      "\t терпковатый терп ко ва тый терп ко ва тый\n",
      "Saving model...\n",
      "Saved in checkpoints/checkpoint_09.11.16_15:36\n",
      "Starting epoch 61\n",
      "Epoch 61 done. Loss: 0.007455381099134684. Training took 13.700926303863525 sec.\n",
      "Validation loss: 0.2150532305240631\n",
      "Accuracy: 0.745\n",
      "Sample predictions:\n",
      "\t пироманьяк пи ро мань як пи ро мань як\n",
      "\t оттопыриваться от то пы ри вать ся от то пы ри вать ся\n",
      "\t озадачиться о за да чить ся о за да чить ся\n",
      "Starting epoch 62\n",
      "Epoch 62 done. Loss: 0.008030875585973263. Training took 13.701658725738525 sec.\n",
      "Validation loss: 0.21122509241104126\n",
      "Accuracy: 0.765\n",
      "Sample predictions:\n",
      "\t зашершаветь за шер ша веть за шер ша веть\n",
      "\t рыб рыб рыб\n",
      "\t хосомаки хо со ма ки хо со ма ки\n",
      "Starting epoch 63\n",
      "Epoch 63 done. Loss: 0.008062690496444702. Training took 13.673120021820068 sec.\n",
      "Validation loss: 0.20261505246162415\n",
      "Accuracy: 0.755\n",
      "Sample predictions:\n",
      "\t финансистка фи нан сист ка фи нан сист ка\n",
      "\t оттопыриваться от то пы ри вать ся от то пы ри вать ся\n",
      "\t ошепеляветь о ше пе ля веть о ше пе ля веть\n",
      "Starting epoch 64\n",
      "Epoch 64 done. Loss: 0.007600609678775072. Training took 13.670995712280273 sec.\n",
      "Validation loss: 0.21290013194084167\n",
      "Accuracy: 0.73\n",
      "Sample predictions:\n",
      "\t биохорология би о хо ро ло ги я би о хо ро ло ги я\n",
      "\t брэд брэд брэд\n",
      "\t ссять ссять ссять\n",
      "Starting epoch 65\n",
      "Epoch 65 done. Loss: 0.007196969352662563. Training took 13.695460796356201 sec.\n",
      "Validation loss: 0.22039176523685455\n",
      "Accuracy: 0.765\n",
      "Sample predictions:\n",
      "\t расхватывать рас хва ты вать рас хва ты вать\n",
      "\t узкосословный узко со слов ный уз ко со слов ный\n",
      "\t кратима кра ти ма кра ти ма\n",
      "Starting epoch 66\n",
      "Epoch 66 done. Loss: 0.006996762938797474. Training took 13.7352614402771 sec.\n",
      "Validation loss: 0.20488204061985016\n",
      "Accuracy: 0.77\n",
      "Sample predictions:\n",
      "\t микромем мик ро мем мик ро мем\n",
      "\t препуциопластика пре пу ци о плас ти ка пре пу ци о пла сти ка\n",
      "\t альмквист альмквист альмквист\n",
      "Starting epoch 67\n",
      "Epoch 67 done. Loss: 0.006970847956836224. Training took 13.676064729690552 sec.\n",
      "Validation loss: 0.21569111943244934\n",
      "Accuracy: 0.76\n",
      "Sample predictions:\n",
      "\t дипилонский ди пи лон ский ди пи лон ский\n",
      "\t варфарин вар фа рин вар фа рин\n",
      "\t алкиловый ал ки ло вый ал ки ло вый\n",
      "Starting epoch 68\n",
      "Epoch 68 done. Loss: 0.006685818079859018. Training took 13.663380861282349 sec.\n",
      "Validation loss: 0.228896364569664\n",
      "Accuracy: 0.715\n",
      "Sample predictions:\n",
      "\t ссять ссять ссять\n",
      "\t вертикализация вер ти ка ли за ци я вер ти ка ли за ци я\n",
      "\t обрученница об ручен ни ца об ру чен ни ца\n",
      "Starting epoch 69\n",
      "Epoch 69 done. Loss: 0.006589934695512056. Training took 13.571579933166504 sec.\n",
      "Validation loss: 0.21840186417102814\n",
      "Accuracy: 0.735\n",
      "Sample predictions:\n",
      "\t депроприатив де про при а тив де про при а тив\n",
      "\t отщетить от ще тить о тще тить\n",
      "\t оттопыриваться от то пы ри вать ся от то пы ри вать ся\n",
      "Starting epoch 70\n",
      "Epoch 70 done. Loss: 0.00748239504173398. Training took 13.591086149215698 sec.\n",
      "Validation loss: 0.22684668004512787\n",
      "Accuracy: 0.76\n",
      "Sample predictions:\n",
      "\t пироманьяк пи ро ман ь як пи ро мань як\n",
      "\t насолодеть на со ло деть на со ло деть\n",
      "\t непрочитанный не про чи тан ный не про чи тан ный\n",
      "Saving model...\n",
      "Saved in checkpoints/checkpoint_09.11.16_15:39\n",
      "Starting epoch 71\n",
      "Epoch 71 done. Loss: 0.007871665991842747. Training took 13.660129070281982 sec.\n",
      "Validation loss: 0.2175736129283905\n",
      "Accuracy: 0.74\n",
      "Sample predictions:\n",
      "\t препуциопластика пре пу ци о пласти ка пре пу ци о пла сти ка\n",
      "\t типок ти пок ти пок\n",
      "\t амфиартроз ам фи артроз ам фи ар троз\n",
      "Starting epoch 72\n",
      "Epoch 72 done. Loss: 0.00703410105779767. Training took 13.665306806564331 sec.\n",
      "Validation loss: 0.2270059585571289\n",
      "Accuracy: 0.745\n",
      "Sample predictions:\n",
      "\t флайер флай ер флай ер\n",
      "\t флайер флай ер флай ер\n",
      "\t узкосословный уз ко со слов ный уз ко со слов ный\n",
      "Starting epoch 73\n",
      "Epoch 73 done. Loss: 0.006602957379072905. Training took 13.65950632095337 sec.\n",
      "Validation loss: 0.2181134819984436\n",
      "Accuracy: 0.77\n",
      "Sample predictions:\n",
      "\t пропагандируемый про па ган ди ру е мый про па ган ди ру е мый\n",
      "\t геохорология ге о хо ро ло ги я ге о хо ро ло ги я\n",
      "\t йыгъ йыгъ йыгъ\n",
      "Starting epoch 74\n",
      "Epoch 74 done. Loss: 0.006224233191460371. Training took 13.67410659790039 sec.\n",
      "Validation loss: 0.21391892433166504\n",
      "Accuracy: 0.805\n",
      "Sample predictions:\n",
      "\t лимнобиос ли мно би ос лим но би ос\n",
      "\t контрамаркированный кон тра мар ки ро ван ный кон тра мар ки ро ван ный\n",
      "\t михайловский ми хай лов ский ми хай лов ский\n",
      "Starting epoch 75\n",
      "Epoch 75 done. Loss: 0.005900621879845858. Training took 13.692015647888184 sec.\n",
      "Validation loss: 0.21813809871673584\n",
      "Accuracy: 0.81\n",
      "Sample predictions:\n",
      "\t дирк дирк дирк\n",
      "\t тромбообразование тром бо об ра зо ва ни е тром бо об ра зо ва ни е\n",
      "\t хуина ху и на ху и на\n",
      "Starting epoch 76\n",
      "Epoch 76 done. Loss: 0.005959993228316307. Training took 13.676801443099976 sec.\n",
      "Validation loss: 0.21485379338264465\n",
      "Accuracy: 0.815\n",
      "Sample predictions:\n",
      "\t интерлиньяжный ин тер линь яж ный ин тер линь яж ный\n",
      "\t светопреставленье све то пре став ле нь е све то пре став ле нье\n",
      "\t потарахтеть по та рах теть по та рах теть\n",
      "Starting epoch 77\n",
      "Epoch 77 done. Loss: 0.00690875668078661. Training took 13.680906057357788 sec.\n",
      "Validation loss: 0.20948049426078796\n",
      "Accuracy: 0.77\n",
      "Sample predictions:\n",
      "\t полуобезумевший по лу о бе з у ме в ший по лу о бе зу мев ший\n",
      "\t постоперационный пос то пе ра ци он ный пост о пе ра ци он ный\n",
      "\t брэд брэд брэд\n",
      "Starting epoch 78\n",
      "Epoch 78 done. Loss: 0.006684122607111931. Training took 13.685396671295166 sec.\n",
      "Validation loss: 0.21340599656105042\n",
      "Accuracy: 0.81\n",
      "Sample predictions:\n",
      "\t мембот мембот мем бот\n",
      "\t дипломирование ди пло ми ро ва ни е ди пло ми ро ва ни е\n",
      "\t брехаться бре хать ся бре хать ся\n",
      "Starting epoch 79\n",
      "Epoch 79 done. Loss: 0.006748049519956112. Training took 13.64616060256958 sec.\n",
      "Validation loss: 0.21858030557632446\n",
      "Accuracy: 0.785\n",
      "Sample predictions:\n",
      "\t микромем мик ро мем мик ро мем\n",
      "\t непрочитанный не про чи тан ный не про чи тан ный\n",
      "\t потарахтеть по та рах теть по та рах теть\n",
      "Starting epoch 80\n",
      "Epoch 80 done. Loss: 0.0074582407251000404. Training took 13.637435913085938 sec.\n",
      "Validation loss: 0.22210416197776794\n",
      "Accuracy: 0.76\n",
      "Sample predictions:\n",
      "\t горю го рю горю\n",
      "\t ошепеляветь о ше пе ля веть о ше пе ля веть\n",
      "\t подкрашивать под кра ши вать под кра ши вать\n",
      "Saving model...\n",
      "Saved in checkpoints/checkpoint_09.11.16_15:41\n",
      "Starting epoch 81\n",
      "Epoch 81 done. Loss: 0.006483026314526796. Training took 13.666183471679688 sec.\n",
      "Validation loss: 0.21697849035263062\n",
      "Accuracy: 0.775\n",
      "Sample predictions:\n",
      "\t подзадолбать под за дол бать под за дол бать\n",
      "\t раздробиться раз дро бить ся раз дро бить ся\n",
      "\t пятиячейник пя ти я чей ник пя ти я чей ник\n",
      "Starting epoch 82\n",
      "Epoch 82 done. Loss: 0.005612435285001993. Training took 13.666749477386475 sec.\n",
      "Validation loss: 0.22328555583953857\n",
      "Accuracy: 0.79\n",
      "Sample predictions:\n",
      "\t рыб рыб рыб\n",
      "\t дошивать до ши вать до ши вать\n",
      "\t альмквист альмквист альмквист\n",
      "Starting epoch 83\n",
      "Epoch 83 done. Loss: 0.0054643782787024975. Training took 13.66438364982605 sec.\n",
      "Validation loss: 0.22676080465316772\n",
      "Accuracy: 0.78\n",
      "Sample predictions:\n",
      "\t терпковатый терп ко ва тый терп ко ва тый\n",
      "\t чертящийся чер тя щий ся чер тя щий ся\n",
      "\t алюмогелевый а лю мо ге ле вый а лю мо ге ле вый\n",
      "Starting epoch 84\n",
      "Epoch 84 done. Loss: 0.00558039965108037. Training took 13.626200914382935 sec.\n",
      "Validation loss: 0.2289642095565796\n",
      "Accuracy: 0.79\n",
      "Sample predictions:\n",
      "\t перевёрстывавшийся пе ре вёр сты ва вший ся пе ре вёр сты вав ший ся\n",
      "\t чертящийся чер тя щий ся чер тя щий ся\n",
      "\t рыб рыб рыб\n",
      "Starting epoch 85\n",
      "Epoch 85 done. Loss: 0.006528734695166349. Training took 13.616971015930176 sec.\n",
      "Validation loss: 0.22019237279891968\n",
      "Accuracy: 0.8\n",
      "Sample predictions:\n",
      "\t раннеголоценовый ран не го ло це но вый ран не го ло це но вый\n",
      "\t русица ру си ца ру си ца\n",
      "\t дипломирование дипло ми ро ва ни е ди пло ми ро ва ни е\n",
      "Starting epoch 86\n",
      "Epoch 86 done. Loss: 0.006263758055865765. Training took 13.625911951065063 sec.\n",
      "Validation loss: 0.2113560140132904\n",
      "Accuracy: 0.78\n",
      "Sample predictions:\n",
      "\t понаглеть по наг леть по на глеть\n",
      "\t алкиловый ал ки ло вый ал ки ло вый\n",
      "\t падали па да ли па да ли\n",
      "Starting epoch 87\n",
      "Epoch 87 done. Loss: 0.005985254421830177. Training took 13.62355351448059 sec.\n",
      "Validation loss: 0.2171725481748581\n",
      "Accuracy: 0.795\n",
      "Sample predictions:\n",
      "\t штормгласс шторм гласс шторм гласс\n",
      "\t хуина ху и на ху и на\n",
      "\t подкрашивать под кра ши вать под кра ши вать\n",
      "Starting epoch 88\n",
      "Epoch 88 done. Loss: 0.005571995861828327. Training took 13.62234878540039 sec.\n",
      "Validation loss: 0.22214163839817047\n",
      "Accuracy: 0.82\n",
      "Sample predictions:\n",
      "\t искусывание ис ку сы ва ни е ис ку сы ва ни е\n",
      "\t застуденеть за сту де неть за сту де неть\n",
      "\t лимнобиос ли мно би ос лим но би ос\n",
      "Starting epoch 89\n",
      "Epoch 89 done. Loss: 0.005223769694566727. Training took 13.66772174835205 sec.\n",
      "Validation loss: 0.22460898756980896\n",
      "Accuracy: 0.805\n",
      "Sample predictions:\n",
      "\t бередя бе ре дя бе ре дя\n",
      "\t тромбообразование тром бо об ра зо ва ни е тром бо об ра зо ва ни е\n",
      "\t брехаться бре хать ся бре хать ся\n",
      "Starting epoch 90\n",
      "Epoch 90 done. Loss: 0.004886193200945854. Training took 13.67431902885437 sec.\n",
      "Validation loss: 0.22572055459022522\n",
      "Accuracy: 0.795\n",
      "Sample predictions:\n",
      "\t горю го рю горю\n",
      "\t аспарагинат аспа ра ги нат ас па ра ги нат\n",
      "\t понаглеть по наг леть по на глеть\n",
      "Saving model...\n",
      "Saved in checkpoints/checkpoint_09.11.16_15:43\n",
      "Starting epoch 91\n",
      "Epoch 91 done. Loss: 0.004907913506031036. Training took 13.621394634246826 sec.\n",
      "Validation loss: 0.22902759909629822\n",
      "Accuracy: 0.78\n",
      "Sample predictions:\n",
      "\t брехаться бре хаться бре хать ся\n",
      "\t застуденеть за сту де неть за сту де неть\n",
      "\t целочка це лоч ка це лоч ка\n",
      "Starting epoch 92\n",
      "Epoch 92 done. Loss: 0.006104751024395227. Training took 13.62671709060669 sec.\n",
      "Validation loss: 0.21784567832946777\n",
      "Accuracy: 0.785\n",
      "Sample predictions:\n",
      "\t хосомаки хо со ма ки хо со ма ки\n",
      "\t страгивать стра ги вать стра ги вать\n",
      "\t неизбирательный не из би ра тель ный не из би ра тель ный\n",
      "Starting epoch 93\n",
      "Epoch 93 done. Loss: 0.006626847665756941. Training took 13.627117395401001 sec.\n",
      "Validation loss: 0.21896742284297943\n",
      "Accuracy: 0.77\n",
      "Sample predictions:\n",
      "\t кратима кра ти ма кра ти ма\n",
      "\t всклянь всклянь всклянь\n",
      "\t ссять ссять ссять\n",
      "Starting epoch 94\n",
      "Epoch 94 done. Loss: 0.007186007685959339. Training took 13.623557329177856 sec.\n",
      "Validation loss: 0.23024982213974\n",
      "Accuracy: 0.76\n",
      "Sample predictions:\n",
      "\t коме коме ко ме\n",
      "\t дирк дирк дирк\n",
      "\t деонимический де о ни ми чес кий де о ни ми че ский\n",
      "Starting epoch 95\n",
      "Epoch 95 done. Loss: 0.006633314769715071. Training took 13.618114709854126 sec.\n",
      "Validation loss: 0.22575682401657104\n",
      "Accuracy: 0.78\n",
      "Sample predictions:\n",
      "\t контрамаркированный кон тра мар ки ро ван ный кон тра мар ки ро ван ный\n",
      "\t целочка це лоч ка це лоч ка\n",
      "\t душевладелец ду ше вла делец ду ше вла де лец\n",
      "Starting epoch 96\n",
      "Epoch 96 done. Loss: 0.005628461018204689. Training took 13.637343168258667 sec.\n",
      "Validation loss: 0.22183333337306976\n",
      "Accuracy: 0.795\n",
      "Sample predictions:\n",
      "\t деонимический де о ни ми чес кий де о ни ми че ский\n",
      "\t препуциопластика пре пу ци о плас ти ка пре пу ци о пла сти ка\n",
      "\t нут нут нут\n",
      "Starting epoch 97\n",
      "Epoch 97 done. Loss: 0.005258143879473209. Training took 13.634922981262207 sec.\n",
      "Validation loss: 0.22345030307769775\n",
      "Accuracy: 0.795\n",
      "Sample predictions:\n",
      "\t сытеть сы теть сы теть\n",
      "\t душевладелец ду ше вла делец ду ше вла де лец\n",
      "\t просвиристеть про сви рис теть про сви рис теть\n",
      "Starting epoch 98\n",
      "Epoch 98 done. Loss: 0.004613297060132027. Training took 13.706212282180786 sec.\n",
      "Validation loss: 0.22117123007774353\n",
      "Accuracy: 0.79\n",
      "Sample predictions:\n",
      "\t брехаться бре хать ся бре хать ся\n",
      "\t душевладелец ду ше вла делец ду ше вла де лец\n",
      "\t сленгизм слен гизм слен гизм\n",
      "Starting epoch 99\n",
      "Epoch 99 done. Loss: 0.004343744833022356. Training took 13.691921949386597 sec.\n",
      "Validation loss: 0.22283659875392914\n",
      "Accuracy: 0.795\n",
      "Sample predictions:\n",
      "\t проскопия про ско пи я про ско пи я\n",
      "\t обрученница об ру чен ни ца об ру чен ни ца\n",
      "\t амфиартроз ам фи артроз ам фи ар троз\n"
     ]
    }
   ],
   "source": [
    "parser = SyllableParser(num_epochs=100, batch_size=200, cell_type='gru', treshold=0.5)\n",
    "trained_sess = parser.train('normal_syllables.txt', 'checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling...\n",
      "в в\n",
      "израиль из раиль\n",
      "дама дама\n",
      "ус ус\n",
      "хгапп хгапп\n",
      "антк антк\n",
      "ао ао\n",
      "аарон а а рон\n",
      "ессентуки ес сен ту ки\n",
      "еэп еэп\n",
      "ес ес\n",
      "рф рф\n",
      "дата дата\n",
      "япония я по ни я\n",
      "безымянный бе зы мян ный\n",
      "дхм дхм\n",
      "карандаш карандаш\n",
      "алфёров ал фё ров\n",
      "папа па па\n",
      "эвм эвм\n",
      "он он\n",
      "сестра сест ра\n",
      "и и\n",
      "ад ад\n",
      "адаптация а дап та ци я\n",
      "антигистаминный ан ти ги с та мин ный\n",
      "барабан ба ра бан\n",
      "белка бел ка\n",
      "визуализация ви зу а ли за ци я\n",
      "гм гм\n",
      "демократ де мо крат\n",
      "диез ди ез\n",
      "дилетант ди ле тант\n",
      "досуг до суг\n",
      "искусно ис ку сно\n",
      "какао ка ка о\n",
      "медиевистика ме ди е вис ти ка\n",
      "аргон аргон\n",
      "платина пла ти на\n",
      "например на при мер\n",
      "паркетник пар кет ник\n",
      "пиньинь пинь инь\n",
      "полиция по ли ци я\n",
      "дупа ду па\n",
      "язик язик\n",
      "сладенький сла день кий\n",
      "тело те ло\n",
      "улучшение у луч ше ни е\n",
      "утешение у те ше ни е\n",
      "ученье у чень е\n",
      "последовавший по сле до вав ший\n",
      "фламандский фла манд ский\n",
      "экзекуция эк зе ку ци я\n",
      "в в\n",
      "спид спид\n",
      "алгебра алгеб ра\n",
      "двоемыслие дво е мыс ли е\n",
      "г г\n",
      "кенотрон ке но трон\n",
      "пеночка-теньковка пе ноч ка- тень ков ка\n",
      "таннид тан нид\n",
      "литера ли те ра\n",
      "ёлки-палки ёл ки-пал ки\n",
      "австралия австрали я\n",
      "азербайджан а зер бай джан\n",
      "армения ар ме ни я\n",
      "англия ан гли я\n",
      "хорватский хор ват с кий\n",
      "египет е ги пет\n",
      "домбра дом б ра\n",
      "гусли-самогуды гу сли-са мо гу ды\n",
      "скатерть-самобранка ска терть -са мо бран ка\n",
      "кошелёк-самотряс ко ше лёк- са мо тряс\n",
      "сапоги-скороходы са по ги-ско ро хо ды\n",
      "миро ми ро\n",
      "флейта-пикколо флей та - пик ко ло\n",
      "нахлыст на хлыст\n",
      "заполоснуться за по лос нуть ся\n",
      "сразиться сра зить ся\n",
      "допеть до петь\n",
      "тоталитарный то та ли тар ный\n",
      "марксизм-ленинизм марк сизм- ле ни низм\n",
      "коста-рика кос та -ри ка\n",
      "шиншилла шин шил ла\n",
      "булава бу ла ва\n",
      "электрод э ле ктрод\n",
      "до-диез до-ди ез\n",
      "ре-диез ре-ди ез\n",
      "ми-диез ми-ди ез\n",
      "фа-диез фа-ди ез\n",
      "соль-диез соль -ди ез\n",
      "ля-диез ля-ди ез\n",
      "си-диез си-ди ез\n",
      "пчельник пчель ник\n",
      "лето ле то\n",
      "обусловить обу сло вить\n",
      "кокнар кок нар\n",
      "обуславливать о буслав ли вать\n",
      "кунигас ку ни гас\n",
      "спасание спа са ни е\n",
      "познань по знань\n",
      "обочина о бо чи на\n",
      "алексей а лексей\n",
      "литература ли те ра ту ра\n",
      "четьи-минеи четь и- ми не и\n",
      "необычно не о быч но\n",
      "с с\n",
      "афганистан аф гани стан\n",
      "деепричастие де епри час ти е\n",
      "интерлингва ин тер лингва\n",
      "противоречивость про ти во ре чи вость\n",
      "мочеточный мо че точ ный\n",
      "биатлонист би ат ло нист\n",
      "семирамида се ми ра ми да\n",
      "дуодецима ду о де ци ма\n",
      "септима сеп ти ма\n",
      "нона но на\n",
      "децима де ци ма\n",
      "ундецима ун де ци ма\n",
      "терцдецима терц де ци ма\n",
      "квартдецима кварт де цима\n",
      "безобразный без об раз ный\n",
      "хартия хар ти я\n",
      "клоп-солдатик клоп- сол да тик\n",
      "сдерживающий сдер жи ва ю щий\n",
      "европа ев ро па\n",
      "македонский ма ке дон ский\n",
      "во-первых во - пер вых\n",
      "индия ин ди я\n",
      "ангола ан го ла\n",
      "ягня яг ня\n",
      "янина яни на\n",
      "ядвига я дви га\n",
      "ярослава я росла ва\n",
      "юлиана юли а на\n",
      "эльвира эльвира\n",
      "элеонора э ле о но ра\n",
      "эвелина э ве ли на\n",
      "улита у ли та\n",
      "соображение со об ра же ни е\n",
      "аэс аэс\n",
      "зиять зи ять\n",
      "всегда всегда\n",
      "макать ма кать\n",
      "лёгкие лёг ки е\n",
      "б б\n",
      "аруба а ру ба\n",
      "копатель ко па тель\n",
      "идо идо\n",
      "идейный идей ный\n",
      "чсср чсср\n",
      "фронтиспис фрон тис пис\n",
      "валюта ва лю та\n",
      "хз хз\n",
      "августа ав гус та\n",
      "акулина а ку ли на\n",
      "алевтина а лев ти на\n",
      "александра а лек сан дра\n",
      "алиса а лиса\n",
      "алоиза а ло и за\n",
      "ангелина ан ге ли на\n",
      "анета а не та\n",
      "анетта а нет та\n",
      "анжелика анже ли ка\n",
      "ариадна а ри адна\n",
      "антонина ан то ни на\n",
      "антонида ан то ни да\n",
      "аннета ан не та\n",
      "колбасить кол ба сить\n",
      "елейный е лей ный\n",
      "донага до на га\n",
      "павлина пав ли на\n",
      "олимпиада о лим пи ада\n",
      "октябрина ок тя бри на\n",
      "разборчивый раз бор чи вый\n",
      "зыбучий зы бу чий\n",
      "нахапать на ха пать\n",
      "ощетиниться о ще ти ни ть ся\n",
      "измаяться из ма ять ся\n",
      "порхать пор хать\n",
      "отчалить от ча лить\n",
      "плюхаться плю хать ся\n",
      "поплатиться по пла тить ся\n",
      "усесться у сесть ся\n",
      "елена е ле на\n",
      "екатерина е ка те ри на\n",
      "елизавета е ли за ве та\n",
      "зарина за ри на\n",
      "илона и лона\n",
      "ираида и ра и да\n",
      "ирена ире на\n",
      "инесса и несса\n",
      "уморительный у мо ри тель ный\n",
      "кельнер кель нер\n",
      "извилистый из ви листый\n",
      "тауматауакатангиангакоауауотаматеатурипукакапикимаунгахоронукупокануэнуакитанатаху та у ма та у а ка тан ги ан га ко ау а у о та ма те а ту ри пу ка ка пи ки ма ун га хо ро ну ку по ка ну э ну а ки та на та ху\n",
      "пениться пе нить ся\n",
      "андорра андор ра\n",
      "трантелево тран те ле во\n",
      "заляпать за ля пать\n"
     ]
    }
   ],
   "source": [
    "parser.sample(trained_sess, 'untitled.txt', 'test_output.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
